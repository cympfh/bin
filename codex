#!/usr/bin/env python

import json
import subprocess
import sys

import click
from litellm import completion
from pydantic import BaseModel, Field

# reasoning モデルをデフォルトに
LLM_CONFIG = json.loads(
    subprocess.run(["llm-config", "xai"], capture_output=True).stdout.decode("utf-8")
)
LLM_CONFIG["model"] = "grok-4-fast-reasoning"


class CodeOutput(BaseModel):
    language: str = Field(description="Programming language of the code")
    explanation: str = Field(description="Explanation of what the code does")
    code: str = Field(description="Generated or completed code")


class LLM:
    def __init__(self, provider: str, model: str):
        self.model = f"{provider}/{model}"

    def chat(self, language: str, text: str) -> CodeOutput:
        """自然言語で書いてほしいコードを説明する

        生成したコードを得る

        Parameters
        ----------
        language
            プログラミング言語
        text
            説明文
        """
        system_prompt = f"""
プログラミングの手伝いをしてください.
{language} 言語でコーディングをしています.
今からどんなコードを書く必要があるか説明するので, それを実現するコード片を出力してください.

ユーザーは一秒でも早く結果を知りたいので, {language} コードを示す前に御託を述べるような真似は決してしないでください.
そのようなことをする場合, あなたの結果はマイナスに評価されます.
必ず {language} コードのみを出力してください.
コードの前後に ```{language.lower()} や ``` なんかを出力することも本当にやめてください.
"""
        messages = [
            {
                "role": "system",
                "content": system_prompt,
            },
            {
                "role": "user",
                "content": f"""
---
{text}
---
""",
            },
        ]
        result = completion(
            model=self.model,
            messages=messages,
            response_format=CodeOutput,
        )
        content: str = result.choices[0].message.content  # type: ignore
        return CodeOutput.model_validate_json(content)

    def complete(self, language: str, code: str) -> CodeOutput:
        """与えたプログラムコード片のうちプレースホルダーを補完してもらう

        {{ ... }} が補完対象
        生成したコードを得る

        Parameters
        ----------
        language
            プログラミング言語
        code
            プレースホルダーを含むプログラムコード片
        """
        system_prompt = f"""
Goal: プログラミングの手伝い
Prompt: あなたはするべきことは プレースホルダー の 補完 です

Method:
ユーザーはプログラミング言語 ({language}) で書いたコードを示します
ただしこのコードは {{{{ ... }}}} を含んでおり, これがプレースホルダーです.

Example:

fn main() {{
    {{{{ Hello, World! をする }}}}
}}

fn is_odd(n: usize) -> bool {{
    if {{{{}}}} {{
        true
    }} else {{
        false
    }}
}}

Placeholder:
{{{{ と }}}} で括られた文字列
{{{{ と }}}} の間には何も無いかもしれないし, ユーザーの指示が自然言語で書かれてるかもしれない.
もし指示があるなら, それをヒントにして何をプレースホルダーに書くかよく考えて.
プレースホルダーの中身が空の場合は, 周囲のコードから正しく類推して.
あなたは優秀なプログラマです.

Your output:
プレースホルダー全てを埋めたコードを出力する.
以下を満たしている必要がある.

1. プレースホルダーだけが補完され変更されている.
2. 出力はプレースホルダー {{{{ }}}} が登場しない
3. プレースホルダー以外は全く変更されていない

Note:
無定義で現れる関数やマクロはあなたが見えない場所が定義されている
あなたがそれらを使うことは許可されている
"""
        messages = [
            {
                "role": "system",
                "content": system_prompt,
            },
            {
                "role": "user",
                "content": f"""
---
{code}
---
""",
            },
        ]
        result = completion(
            model=self.model,
            messages=messages,
            response_format=CodeOutput,
        )
        content: str = result.choices[0].message.content  # type: ignore
        return CodeOutput.model_validate_json(content)


@click.group()
def main():
    pass


@main.command()
@click.option("--language", "-L", type=str, default="Rust")
@click.option(
    "--provider",
    "-p",
    type=click.Choice(["xai", "gemini", "openai", "anthropic"]),
    default=LLM_CONFIG["provider"],
    show_default=True,
)
@click.option(
    "--model",
    "-m",
    type=str,
    default=LLM_CONFIG["model"],
    show_default=True,
)
@click.option("--quiet", "-q", is_flag=True, default=False)
@click.argument("text", type=str, required=False)
def chat(
    language: str,
    provider: str,
    model: str,
    quiet: bool,
    text: str,
):
    if not text:
        text = sys.stdin.read()
    if not quiet:
        click.secho("Running...", err=True, fg="yellow")
    result = LLM(provider, model).chat(language, text)
    if not quiet:
        click.secho(f"Language: {result.language}", err=True)
        click.secho(f"Explanation: {result.explanation}", err=True)
    print(result.code)


@main.command()
@click.option("--language", "-L", type=str, default="?")
@click.option(
    "--provider",
    "-p",
    type=click.Choice(["xai", "gemini", "openai", "anthropic"]),
    default=LLM_CONFIG["provider"],
    show_default=True,
)
@click.option(
    "--model",
    "-m",
    type=str,
    default=LLM_CONFIG["model"],
    show_default=True,
)
@click.option("--quiet", "-q", is_flag=True, default=False)
@click.argument("src", type=str, required=False)
def complete(
    language: str,
    provider: str,
    model: str,
    quiet: bool,
    src: str,
):
    if src:
        code = open(src, "rt").read()
    else:
        code = sys.stdin.read()
    if not quiet:
        click.secho(f"Using {provider}/{model}", err=True, fg="yellow")
        click.secho("Running...", err=True, fg="yellow")
    result = LLM(provider, model).complete(language, code)
    if not quiet:
        click.secho(f"Language: {result.language}", err=True)
        click.secho(f"Explanation: {result.explanation}", err=True)
    print(result.code)


if __name__ == "__main__":
    main()
