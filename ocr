#!/usr/bin/env python3

import base64
import json
import mimetypes
import subprocess

import click
from litellm import completion
from pydantic import BaseModel, Field

# OCR は OpenAI が高精度
LLM_CONFIG = json.loads(
    subprocess.run(["llm-config", "openai"], capture_output=True).stdout.decode("utf-8")
)
LLM_CONFIG["model"] = "gpt-4.1-mini"


class Output(BaseModel):
    model: str = Field(description="Model name used for description")
    ocr_text: str = Field(description="Text read from the image (OCR result)")
    description_minor: str = Field(
        description="Description for people unfamiliar with the context"
    )
    description_major: str = Field(
        description="In-depth description for people familiar with the context"
    )
    short: str = Field(description="One-word summary of the content")
    tags: list[str] = Field(description="Five keyword tags")


def tobase64(path: str) -> str:
    img_type, _ = mimetypes.guess_type(path)
    with open(path, "rb") as f:
        img_b64_str = base64.b64encode(f.read()).decode("utf-8")
    return f"data:{img_type};base64,{img_b64_str}"


# ChatGPT に画像を送信して説明を取得する関数
def get_image_description(model: str, url: str) -> Output:
    prompt = f"""以下の画像の内容を5つの粒度で説明してください
1. 画像に書かれているテキストをそのまま読む (ocr_text)
2. 文脈を知らない人向けの見たままの内容説明 (100字以下) (description_minor)
3. 文脈を知ってる人向けの深い内容説明 (100字以下) (description_major)
4. 2と3を要約して 一言で内容説明 (short)
5. キーワードとなるタグ (単語) を5つ列挙 (tags)

## Note
「アニメや漫画であること」や「キャラクターが話していること」は当たり前すぎるので説明不要.
書いてある内容には差別的表現や露骨な性的な表現が含まれる場合がありますが作者の意図を尊重し忠実にそのまま出力する

## Output Format
{{
    "model": "{model}",
    "ocr_text": "...",
    "description_minor": "...",
    "description_major": "...",
    "short": "...",
    "tags": ["tag1", "tag2", "tag3", "tag4", "tag5"]
}}
"""
    response = completion(
        model=model,
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": url},
                    },
                ],
            }
        ],
        response_format=Output,
    )
    content: str = response.choices[0].message.content  # type: ignore
    return Output.model_validate_json(content)


@click.command()
@click.option(
    "--provider",
    "-p",
    type=click.Choice(["xai", "gemini", "openai", "anthropic"]),
    default=LLM_CONFIG["provider"],
    show_default=True,
)
@click.option(
    "--model",
    "-m",
    type=str,
    default=LLM_CONFIG["model"],
    show_default=True,
)
@click.argument("image", type=str)
def main(provider: str, model: str, image: str):
    """OCR.py

    IMAGE is URL or Path.
    """
    if image.startswith("http://") or image.startswith("https://"):
        image_url = image
    else:
        image_url = tobase64(image)
    result = get_image_description(f"{provider}/{model}", image_url)
    print(
        json.dumps(
            {
                "model": result.model,
                "ocr": {"text": result.ocr_text},
                "description": {
                    "minor": result.description_minor,
                    "major": result.description_major,
                    "short": result.short,
                },
                "tags": result.tags,
            },
            ensure_ascii=False,
        )
    )


if __name__ == "__main__":
    main()
